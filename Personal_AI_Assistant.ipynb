{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "2f2391fa",
      "metadata": {
        "id": "2f2391fa"
      },
      "source": [
        "#  Personal AI Assistant in Google Colab (No OpenAI Key Needed)\n",
        "This notebook will help you and your students build a simple **AI Assistant** using open-source models (no API key required)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b43c26e3",
      "metadata": {
        "id": "b43c26e3"
      },
      "source": [
        "## Step 1: Install Transformers\n",
        "We will use Hugging Face Transformers library to run free AI models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "15faba37",
      "metadata": {
        "id": "15faba37"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torch accelerate -q"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7ff3c90",
      "metadata": {
        "id": "b7ff3c90"
      },
      "source": [
        "## Step 2: Import a Model\n",
        "We will use Google's **Flan-T5 Small** model for Q&A and chat."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "55f578ea",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55f578ea",
        "outputId": "e46613db-b03e-4f1f-e55b-13d17df200a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load a small open-source model\n",
        "assistant = pipeline('text2text-generation', model='google/flan-t5-small')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "68a09f6f",
      "metadata": {
        "id": "68a09f6f"
      },
      "source": [
        "## Step 3: Build a Chat Function\n",
        "This function keeps track of chat history and generates AI responses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "752f053d",
      "metadata": {
        "id": "752f053d"
      },
      "outputs": [],
      "source": [
        "chat_history = []\n",
        "\n",
        "def ask_ai(user_input):\n",
        "    global chat_history\n",
        "    # Add user input to history\n",
        "    chat_history.append(f'User: {user_input}')\n",
        "\n",
        "    # Use last 5 turns as context\n",
        "    context = '\\n'.join(chat_history[-5:])\n",
        "\n",
        "    # Generate response\n",
        "    response = assistant(context)[0]['generated_text']\n",
        "\n",
        "    # Save response\n",
        "    chat_history.append(f'Assistant: {response}')\n",
        "    return response"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90ff65d0",
      "metadata": {
        "id": "90ff65d0"
      },
      "source": [
        "## Step 4: Chat with Your Assistant\n",
        "Now you can chat with your AI assistant directly in Colab. Type 'exit' to stop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "de7c7594",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de7c7594",
        "outputId": "88cdb56d-f11a-4b05-96fb-924db2cfd346"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: DSCE Student\n",
            "ðŸ¤– Assistant: User: DSCE\n",
            "You: II am DSCE Student\n",
            "ðŸ¤– Assistant: Assistant: User: II am DSCE Student\n",
            "You: ok bye\n",
            "ðŸ¤– Assistant: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User: DSCE Student Assistant: User:\n",
            "You: exit\n",
            "ðŸ‘‹ Assistant: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "while True:\n",
        "    user_input = input('You: ')\n",
        "    if user_input.lower() in ['exit', 'quit', 'bye']:\n",
        "        print('ðŸ‘‹ Assistant: Goodbye!')\n",
        "        break\n",
        "    reply = ask_ai(user_input)\n",
        "    print('ðŸ¤– Assistant:', reply)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}